startPort: 10000
healthCheckTimeout: 1200
logLevel: debug
macros:
  "llama-server": |-
    ./llama-server --port ${PORT}
  SLOTS: 2
models:
  Qwen3-30B-A3B-Thinking-2507.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Thinking-2507.Q5_K_M.gguf
        --ctx-size 131072  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M.gguf
        --ctx-size 131072  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3-Silent-Scream-6B.i1-Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-Silent-Scream-6B.i1-Q6_K.gguf
        --ctx-size 32768  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K.gguf
        --ctx-size 32768  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K.gguf
        --ctx-size 32768  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  Fallen-Gemma3-27B-v1.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Fallen-Gemma3-27B-v1.i1-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  MN-DARKEST-UNIVERSE-29B_Q4_K_M:
    cmd: |-
      ${llama-server}
        -hf DavidAU/MN-DARKEST-UNIVERSE-29B-GGUF:Q4_K_M
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  gemma-3-4b-it-UD-Q6_K_XL:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-4b-it-UD-Q6_K_XL.gguf
        --ctx-size 131072  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  gemma-3-12b-it-qat-UD-Q6_K_XL:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-12b-it-qat-UD-Q6_K_XL.gguf
        --ctx-size 131072  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  gemma-3-27b-it-qat-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-27b-it-qat-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3-30B-A3B-Instruct-2507.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Instruct-2507.Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3-42B-A3B-Stranger-Thoughts-Deep20x-Abliterated-Uncensored.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-42B-A3B-Stranger-Thoughts-Deep20x-Abliterated-Uncensored.Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  gpt-oss-20b_MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -hf lmstudio-community/gpt-oss-20b-GGUF
        --ctx-size 65535  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  gpt-oss-120b_MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -hf lmstudio-community/gpt-oss-120b-GGUF
        --ctx-size 65535  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00001-of-00002.gguf
        --ctx-size 131072  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  bge-large-en-v1.5.i1-Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/bge-large-en-v1.5.i1-Q6_K.gguf
        --embedding
    env:
    - CUDA_VISIBLE_DEVICES=2
  Qwen3.5-27B-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3.5-27B-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3.5-35B-A3B-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3.5-35B-A3B-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3.5-27B-heretic-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3.5-27B-heretic-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  qwen3-next-80b-a3b-thinking-mxfp4_moe:
    cmd: |-
      ${llama-server}
        -m /models/qwen3-next-80b-a3b-thinking-mxfp4_moe.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Big-Tiger-Gemma-27B-v3-heretic.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Big-Tiger-Gemma-27B-v3-heretic.i1-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Llama-3.3-8B-Instruct-128K-heretic.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Llama-3.3-8B-Instruct-128K-heretic.Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  gpt-oss-20b-uncensored-heretic.i1-MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -m /models/gpt-oss-20b-uncensored-heretic.i1-MXFP4_MOE.gguf
        --ctx-size 65535  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  gpt-oss-120b-heretic-v1.i1-MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -m /models/gpt-oss-120b-heretic-v1.i1-MXFP4_MOE.gguf
        --ctx-size 65535  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3-VL-8B-Thinking-heretic-imatrix-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-VL-8B-Thinking-heretic-imatrix-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  Qwen3-VL-8B-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-VL-8B-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=2
  Qwen3.5-35B-A3B-heretic.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3.5-35B-A3B-heretic.Q5_K_M.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
  Qwen3.5-122B-A10B-abliterated-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3.5-122B-A10B-abliterated-Q4_K_M-00001-of-00002.gguf
        --ctx-size 65536  --jinja
    env:
    - CUDA_VISIBLE_DEVICES=0,1
groups:
  embedders:
    swap: false
    exclusive: false
    members:
    - bge-large-en-v1.5.i1-Q6_K
  qwens:
    swap: false
    exclusive: false
    members:
    - Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M
    - Qwen3-30B-A3B-Thinking-2507.Q5_K_M
    - Qwen3-30B-A3B-Instruct-2507.Q5_K_M
    - Qwen3-Silent-Scream-6B.i1-Q6_K
    - Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K
    - Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K
    - Qwen3-4B-Thinking-2507.Q6_K
    - Qwen_Qwen3-4B-Instruct-2507-Q6_K_L
    - Qwen3.5-27B-heretic-Q5_K_M
  llamas:
    swap: false
    exclusive: false
    members:
    - L3.1-4x8b_BlackTower_RP-V1.1-Uncensored.i1-Q4_K_M
    - L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M
    - L3.1-MOE-4X8B-Dark-Reasoning-Dark-Planet-Hermes-R1-Uncensored-e32-25B.Q6_K
  ds:
    swap: false
    exclusive: false
    members:
    - DeepSeek-R1-Distill-Llama-70B-Uncensored-v2-Unbiased.i1-Q4_K_M
    - DeepSeek-R1-Distill-Qwen-32B-Q4_K_M
  openais:
    swap: false
    exclusive: false
    members:
    - OpenAi-GPT-oss-36B-BrainStorm20x-uncensored.i1-Q5_K_M
    - gpt-oss-120b_MXFP4_MOE
    - gpt-oss-20b_MXFP4_MOE
  gemmas:
    swap: false
    exclusive: false
    members:
    - Fallen-Gemma3-27B-v1.i1-Q5_K_M
    - amoral-gemma3-27B-v2-qat.Q5_K_M
    - gemma-3-27b-it-qat-Q5_K_M
    - gemma-3-12b-it-qat-UD-Q6_K_XL
    - gemma-3-4b-it-UD-Q6_K_XL
  big:
    swap: false
    exclusive: false
    members:
    - Hermes-4-70B-Q4_K_M
    - meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M
