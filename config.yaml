startPort: 10000
healthCheckTimeout: 1200
logLevel: debug
macros:
  "llama-server": |-
    ./llama-server --port ${PORT}
  SLOTS: 2
models:
  Qwen3-30B-A3B-Thinking-2507.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Thinking-2507.Q5_K_M.gguf
        --ctx-size 131072  --jinja
  Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M.gguf
        --ctx-size 131072  --jinja
  OpenAi-GPT-oss-36B-BrainStorm20x-uncensored.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/OpenAi-GPT-oss-36B-BrainStorm20x-uncensored.i1-Q5_K_M.gguf
        --ctx-size 131072  --jinja
  Qwen3-4B-Thinking-2507.Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-4B-Thinking-2507.Q6_K.gguf
        --ctx-size 131072  --jinja
  Qwen_Qwen3-4B-Instruct-2507-Q6_K_L:
    cmd: |-
      ${llama-server}
        -m /models/Qwen_Qwen3-4B-Instruct-2507-Q6_K_L.gguf
        --ctx-size 131072  --jinja
  L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M.gguf
        --ctx-size 65536  --jinja
  Qwen3-Silent-Scream-6B.i1-Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-Silent-Scream-6B.i1-Q6_K.gguf
        --ctx-size 32768  --jinja
  Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K.gguf
        --ctx-size 32768  --jinja
  Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K.gguf
        --ctx-size 32768  --jinja
  Fallen-Gemma3-27B-v1.i1-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Fallen-Gemma3-27B-v1.i1-Q5_K_M.gguf
        --ctx-size 65536  --jinja
  amoral-gemma3-27B-v2-qat.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/amoral-gemma3-27B-v2-qat.Q5_K_M.gguf
        --ctx-size 65536  --jinja
  MN-DARKEST-UNIVERSE-29B_Q4_K_M:
    cmd: |-
      ${llama-server}
        -hf DavidAU/MN-DARKEST-UNIVERSE-29B-GGUF:Q4_K_M
        --ctx-size 65536  --jinja
  DeepSeek-R1-Distill-Qwen-32B-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/DeepSeek-R1-Distill-Qwen-32B-Q4_K_M.gguf
        --ctx-size 32768  --jinja
  Qwen3-32B-Uncensored.Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-32B-Uncensored.Q4_K_M.gguf
        --ctx-size 32768  --jinja
  OpenThinker2-32B-Uncensored.Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/OpenThinker2-32B-Uncensored.Q4_K_M.gguf
        --ctx-size 65536  --jinja
  gemma-3-4b-it-UD-Q6_K_XL:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-4b-it-UD-Q6_K_XL.gguf
        --ctx-size 131072  --jinja
  gemma-3-12b-it-qat-UD-Q6_K_XL:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-12b-it-qat-UD-Q6_K_XL.gguf
        --ctx-size 131072  --jinja
  gemma-3-27b-it-qat-Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-27b-it-qat-Q5_K_M.gguf
        --ctx-size 65536  --jinja
  Hermes-4-70B-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Hermes-4-70B-Q4_K_M.gguf
        --ctx-size 65536  --jinja
  L3.1-MOE-4X8B-Dark-Reasoning-Dark-Planet-Hermes-R1-Uncensored-e32-25B.Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/L3.1-MOE-4X8B-Dark-Reasoning-Dark-Planet-Hermes-R1-Uncensored-e32-25B.Q6_K.gguf
        --ctx-size 65536  --jinja
  DeepSeek-R1-Distill-Llama-70B-Uncensored-v2-Unbiased.i1-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/DeepSeek-R1-Distill-Llama-70B-Uncensored-v2-Unbiased.i1-Q4_K_M.gguf
        --ctx-size 65536  --jinja
  Qwen3-30B-A3B-Instruct-2507.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Instruct-2507.Q5_K_M.gguf
        --ctx-size 65536  --jinja
  Qwen3-42B-A3B-Stranger-Thoughts-Deep20x-Abliterated-Uncensored.Q5_K_M:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-42B-A3B-Stranger-Thoughts-Deep20x-Abliterated-Uncensored.Q5_K_M.gguf
        --ctx-size 65536  --jinja
  L3.1-4x8b_BlackTower_RP-V1.1-Uncensored.i1-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/L3.1-4x8b_BlackTower_RP-V1.1-Uncensored.i1-Q4_K_M.gguf
        --ctx-size 65536  --jinja
  gpt-oss-20b_MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -hf lmstudio-community/gpt-oss-20b-GGUF
        --ctx-size 65535  --jinja
  gpt-oss-120b_MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -hf lmstudio-community/gpt-oss-120b-GGUF
        --ctx-size 65535  --jinja
  meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M:
    cmd: |-
      ${llama-server}
        -m /models/meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00001-of-00002.gguf
        --ctx-size 131072  --jinja
  bge-large-en-v1.5.i1-Q6_K:
    cmd: |-
      ${llama-server}
        -m /models/bge-large-en-v1.5.i1-Q6_K.gguf
        --embedding
groups:
  embedders:
    swap: false
    exclusive: false
    members:
    - bge-large-en-v1.5.i1-Q6_K
  qwens:
    swap: false
    exclusive: false
    members:
    - Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M
    - Qwen3-30B-A3B-Thinking-2507.Q5_K_M
    - Qwen3-30B-A3B-Instruct-2507.Q5_K_M
    - Qwen3-Silent-Scream-6B.i1-Q6_K
    - Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K
    - Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K
    - Qwen3-4B-Thinking-2507.Q6_K
    - Qwen_Qwen3-4B-Instruct-2507-Q6_K_L
  llamas:
    swap: false
    exclusive: false
    members:
    - L3.1-4x8b_BlackTower_RP-V1.1-Uncensored.i1-Q4_K_M
    - L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M
    - L3.1-MOE-4X8B-Dark-Reasoning-Dark-Planet-Hermes-R1-Uncensored-e32-25B.Q6_K
  ds:
    swap: false
    exclusive: false
    members:
    - DeepSeek-R1-Distill-Llama-70B-Uncensored-v2-Unbiased.i1-Q4_K_M
    - DeepSeek-R1-Distill-Qwen-32B-Q4_K_M
  openais:
    swap: false
    exclusive: false
    members:
    - OpenAi-GPT-oss-36B-BrainStorm20x-uncensored.i1-Q5_K_M
    - gpt-oss-120b_MXFP4_MOE
    - gpt-oss-20b_MXFP4_MOE
  gemmas:
    swap: false
    exclusive: false
    members:
    - Fallen-Gemma3-27B-v1.i1-Q5_K_M
    - amoral-gemma3-27B-v2-qat.Q5_K_M
    - gemma-3-27b-it-qat-Q5_K_M
    - gemma-3-12b-it-qat-UD-Q6_K_XL
    - gemma-3-4b-it-UD-Q6_K_XL
  big:
    swap: false
    exclusive: false
    members:
    - Hermes-4-70B-Q4_K_M
    - meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M
