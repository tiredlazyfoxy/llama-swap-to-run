startPort: 10000
healthCheckTimeout: 1200
logLevel: debug
macros:
  "llama-server": |-
    ./llama-server --port ${PORT}
  SLOTS: 2
models:
  Qwen3-30B-A3B-Thinking-2507.Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Thinking-2507.Q5_K_M.gguf
        --ctx-size 131072
  Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M.gguf
        --ctx-size 131072
  OpenAi-GPT-oss-36B-BrainStorm20x-uncensored.i1-Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/OpenAi-GPT-oss-36B-BrainStorm20x-uncensored.i1-Q5_K_M.gguf
        --ctx-size 131072
  Qwen3-4B-Thinking-2507.Q6_K.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-4B-Thinking-2507.Q6_K.gguf
        --ctx-size 131072
  Qwen_Qwen3-4B-Instruct-2507-Q6_K_L.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen_Qwen3-4B-Instruct-2507-Q6_K_L.gguf
        --ctx-size 131072
  L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/L3.3-GeneticLemonade-Final-70B.i1-Q4_K_M.gguf
        --ctx-size 65536
  Qwen3-Silent-Scream-6B.i1-Q6_K.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-Silent-Scream-6B.i1-Q6_K.gguf
        --ctx-size 32768
  Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-Darkest-Jan-v1-256k-ctx-6B.i1-Q6_K.gguf
        --ctx-size 32768
  Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-ST-The-Next-Generation-II-v1-256k-ctx-6B.Q6_K.gguf
        --ctx-size 32768
  Fallen-Gemma3-27B-v1.i1-Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Fallen-Gemma3-27B-v1.i1-Q5_K_M.gguf
        --ctx-size 65536
  amoral-gemma3-27B-v2-qat.Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/amoral-gemma3-27B-v2-qat.Q5_K_M.gguf
        --ctx-size 65536
  MN-DARKEST-UNIVERSE-29B_Q4_K_M:
    cmd: |-
      ${llama-server}
        -hf DavidAU/MN-DARKEST-UNIVERSE-29B-GGUF:Q4_K_M
        --ctx-size 65536
  DeepSeek-R1-Distill-Qwen-32B-Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/DeepSeek-R1-Distill-Qwen-32B-Q4_K_M.gguf
        --ctx-size 32768
  Qwen3-32B-Uncensored.Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-32B-Uncensored.Q4_K_M.gguf
        --ctx-size 32768
  OpenThinker2-32B-Uncensored.Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/OpenThinker2-32B-Uncensored.Q4_K_M.gguf
        --ctx-size 65536
  gemma-3-4b-it-UD-Q6_K_XL.gguf:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-4b-it-UD-Q6_K_XL.gguf
        --ctx-size 131072
  gemma-3-12b-it-qat-UD-Q6_K_XL.gguf:
    cmd: |-
      ${llama-server}
        -m /models/gemma-3-12b-it-qat-UD-Q6_K_XL.gguf
        --ctx-size 131072
  Hermes-4-70B-Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Hermes-4-70B-Q4_K_M.gguf
        --ctx-size 65536
  L3.1-MOE-4X8B-Dark-Reasoning-Dark-Planet-Hermes-R1-Uncensored-e32-25B.Q6_K.gguf:
    cmd: |-
      ${llama-server}
        -m /models/L3.1-MOE-4X8B-Dark-Reasoning-Dark-Planet-Hermes-R1-Uncensored-e32-25B.Q6_K.gguf
        --ctx-size 65536
  DeepSeek-R1-Distill-Llama-70B-Uncensored-v2-Unbiased.i1-Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/DeepSeek-R1-Distill-Llama-70B-Uncensored-v2-Unbiased.i1-Q4_K_M.gguf
        --ctx-size 65536
  Qwen3-30B-A3B-Instruct-2507.Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-30B-A3B-Instruct-2507.Q5_K_M.gguf
        --ctx-size 65536
  Qwen3-42B-A3B-Stranger-Thoughts-Deep20x-Abliterated-Uncensored.Q5_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/Qwen3-42B-A3B-Stranger-Thoughts-Deep20x-Abliterated-Uncensored.Q5_K_M.gguf
        --ctx-size 65536
  L3.1-4x8b_BlackTower_RP-V1.1-Uncensored.i1-Q4_K_M.gguf:
    cmd: |-
      ${llama-server}
        -m /models/L3.1-4x8b_BlackTower_RP-V1.1-Uncensored.i1-Q4_K_M.gguf
        --ctx-size 65536
  gpt-oss-20b_MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -hf lmstudio-community/gpt-oss-20b-GGUF
        --ctx-size 65535
  gpt-oss-120b_MXFP4_MOE:
    cmd: |-
      ${llama-server}
        -hf lmstudio-community/gpt-oss-120b-GGUF
        --ctx-size 65535
groups:
  langgrpah:
    members:
    - Qwen3-30B-A3B-Thinking-2507-Amoral-Edition.i1-Q5_K_M.gguf
    - Qwen3-30B-A3B-Thinking-2507.Q5_K_M.gguf
    - Qwen3-30B-A3B-Instruct-2507.Q5_K_M.gguf
    - Qwen3-Silent-Scream-6B.i1-Q6_K.gguf
  gemmas:
    members:
    - Fallen-Gemma3-27B-v1.i1-Q5_K_M.gguf
    - gemma-3-12b-it-qat-Q6_K_XL.gguf
    - gemma-3-4b-it-Q6_K_XL.gguf
